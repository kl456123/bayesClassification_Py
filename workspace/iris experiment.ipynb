{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = '../dataset/iris/iris_training.csv'\n",
    "TEST_PATH = '../dataset/iris/iris_test.csv'\n",
    "\n",
    "train_dataset = pd.read_csv(TRAIN_PATH,names=['1','2','3','4','label'],dtype={'labels':np.int64})\n",
    "test_dataset = pd.read_csv(TEST_PATH,names=['1','2','3','4','label'],dtype={'labels':np.int64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dataset.drop(0,axis=0,inplace=True)\n",
    "test_dataset.drop(0,axis=0,inplace=True)\n",
    "# test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self,dataset,batch_size,name):\n",
    "        \n",
    "        self.batch_index = 0\n",
    "        self.dataset = dataset\n",
    "#         self.inputs = dataset\n",
    "        self.name = name\n",
    "        self.batch_size = batch_size\n",
    "        self.data_size = dataset.shape[0]\n",
    "        self.left = 1\n",
    "    def next_batch(self):\n",
    "#         no data sample left can be used\n",
    "#         if(self.left==0):\n",
    "#             return \n",
    "#     get the samples of batch_size amount\n",
    "# the head index and end index in dataframe\n",
    "        head = self.batch_index*self.batch_size\n",
    "# check head\n",
    "        if(head>=self.data_size):\n",
    "#             reset it to zero\n",
    "            self.batch_index = 0\n",
    "            head = 0\n",
    "        \n",
    "        end = head + self.batch_size\n",
    "        \n",
    "#         check end if the end is excess the bound of the dataset\n",
    "        if(end > self.data_size):\n",
    "            end = self.data_size\n",
    "#             self.left = 0\n",
    "\n",
    "#             self.batch_index = 0\n",
    "        \n",
    "\n",
    "    \n",
    "#     should convert dataframe to numpy-like array\n",
    "        batch_data = self.dataset[head:end].as_matrix()\n",
    "        \n",
    "        self.batch_index+=1\n",
    "        \n",
    "#         should return the tuple type that contains inputs and labels\n",
    "#       return type (inputs,labels)\n",
    "        return batch_data[:,0:-1].astype(np.float64),batch_data[:,-1].astype(np.int64)\n",
    "\n",
    "    def feed_all(self):\n",
    "        data = self.dataset.as_matrix()\n",
    "        return data[:,0:4].astype(np.float64),data[:,-1].astype(np.int64)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test Dataset class using train_dataset\n",
    "# trainDataset = Dataset(train_dataset,10,'train')\n",
    "# inputs,labels = trainDataset.next_batch()\n",
    "# inputs \n",
    "testDataset = Dataset(test_dataset,12,'test')\n",
    "# inputs ,labels = testDataset.next_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainDataset.next_batch()[1]\n",
    "# a.obj\n",
    "# len(inputs)\n",
    "testDataset.data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def fully_connected_layer(inputs_data,inputs_size,outputs_size,layer_name):\n",
    "# inputs_data is a tensor that is like [batch_size,inputs_size] and if tensor is initial input inputs_size is\n",
    "# the same as feature_number\n",
    "def fully_connected_layer(inputs_data,inputs_size,outputs_size,layer_name):\n",
    "    with tf.name_scope(layer_name):\n",
    "        \n",
    "        Weights = tf.Variable(tf.truncated_normal([inputs_size,outputs_size],\n",
    "                                                  stddev=1.0/math.sqrt(float(inputs_size))),\n",
    "                              name='Weights',\n",
    "                              dtype=tf.float32)\n",
    "    #     biases =[batch_size,outputs_size] (batch_size can be ignored)\n",
    "        biases = tf.Variable(tf.zeros(outputs_size),\n",
    "                            name='biases',dtype=tf.float32)\n",
    "        outputs_data = tf.nn.relu(tf.matmul(inputs_data,Weights) + biases)\n",
    "        return outputs_data\n",
    "\n",
    "def softmax_layer(inputs_data,inputs_size):\n",
    "#     to classify the classes\n",
    "    with tf.name_scope('softmax_layer'):\n",
    "        \n",
    "        outputs_size = 3\n",
    "        Weights = tf.Variable(tf.truncated_normal([inputs_size,outputs_size],\n",
    "                                                  stddev=1.0/math.sqrt(float(inputs_size))),\n",
    "                              name='Weights',\n",
    "                             dtype=tf.float32)\n",
    "    #     biases =[batch_size,outputs_size] (batch_size can be ignored)\n",
    "        biases = tf.Variable(tf.zeros(outputs_size),\n",
    "                            name='biases',\n",
    "                            dtype=tf.float32)\n",
    "\n",
    "        logits = tf.matmul(inputs_data,Weights) + biases\n",
    "    \n",
    "        return logits\n",
    "    \n",
    "def getloss(logits,labels):\n",
    "    \n",
    "#     convert string to int\n",
    "    labels = tf.to_int64(labels)\n",
    "    \n",
    "#     print(labels.get_shape())\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits,labels,\n",
    "                                                   name='xentropy')\n",
    "    loss = tf.reduce_mean(cross_entropy,name='xentropy_mean')\n",
    "    return loss\n",
    "\n",
    "    \n",
    "def inference(inputs_data,hidden_units):\n",
    "#     inputs_size is the same as featrue_number\n",
    "    inputs_size = 4\n",
    "    \n",
    "    for i in range(len(hidden_units)):\n",
    "        \n",
    "        outputs_size = hidden_units[i]\n",
    "        outputs_data  = fully_connected_layer(inputs_data,inputs_size,outputs_size,'layer_'+str(i))\n",
    "        inputs_data = outputs_data\n",
    "        inputs_size = outputs_size\n",
    "    \n",
    "    logits = softmax_layer(outputs_data,inputs_size)\n",
    "    \n",
    "    return logits\n",
    "\n",
    "\n",
    "def evaluate(logits,labels):\n",
    "# return number of correct entries\n",
    "\n",
    "# correct_number is [batch_size] of bool type\n",
    "#     labels = tf.to_int(labels)\n",
    "    labels = tf.to_int64(labels)\n",
    "#     logits = tf.nn.softmax(logits)\n",
    "    correct_number = tf.nn.in_top_k(logits,labels,1)\n",
    "    \n",
    "    return tf.reduce_sum(tf.cast(correct_number,tf.int32))\n",
    "    \n",
    "# def training(loss,\n",
    "#              learning_rate,\n",
    "#              batch_size):\n",
    "# #     track the step\n",
    "#     global_step = tf.Variable(0,name='global_step',trainable=False,dtype=tf.int64)\n",
    "# #     learning_rate_tensor = tf.Variable(learning_rate,name='learning_rate',trainable=False,dtype=tf.float32)\n",
    "#     learning_rate_tensor = tf.train.exponential_decay(learning_rate,\n",
    "#                                                      global_step * batch_size,\n",
    "#                                                      1000,\n",
    "#                                                      0.95)\n",
    "# #     learning_rate_tensor = tf.cond(tf.equal(tf.mod(global_step+1,1000),0),lambda:,lambda:learning_rate_tensor)\n",
    "#     optimizer = tf.train.GradientDescentOptimizer(learning_rate_tensor)\n",
    "    \n",
    "#     train_op = optimizer.minimize(loss,global_step=global_step)\n",
    "# #     train_op = tf.contrib.layers.optimize_loss(optimizer=optimizer,global_step=global_step,loss=loss,learning_rate_decay_fn=tf.train.exponential_decay(decay_rate=0.95,decay_steps=1000),learning_rate=learning_rate)\n",
    "#     return train_op,learning_rate_tensor\n",
    "\n",
    "def learning_policy(learning_rate_base,\n",
    "                    global_step,\n",
    "                    decay_step,\n",
    "                    decay_rate):\n",
    "\n",
    "    decay_size = (global_step+1) / decay_step\n",
    "    learning_rate_now = learning_rate_base *tf.pow(decay_rate,tf.to_float(decay_size))  \n",
    "    return learning_rate_now\n",
    "\n",
    "def training(loss,\n",
    "             learning_rate,\n",
    "            momentum=0.95,\n",
    "            decay_step=4000,\n",
    "            decay_rate=0.1):\n",
    "    \n",
    "#     track steps\n",
    "    global_step = tf.Variable(0,\n",
    "                              dtype=tf.int64,\n",
    "                              name='global_step',\n",
    "                              trainable=False)\n",
    "    \n",
    "#     just store learing_rate ,it should not be modified\n",
    "    learning_rate_base = tf.Variable(learning_rate,\n",
    "                                     dtype=tf.float32,\n",
    "                                     name='learning_rate_base',\n",
    "                                     trainable=False)\n",
    "    \n",
    "#     here we set high parameter in inner\n",
    "    learning_rate_now = learning_policy(learning_rate_base,\n",
    "                                           global_step,\n",
    "                                           decay_step,\n",
    "                                            decay_rate)\n",
    "    \n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate_now,\n",
    "                                           momentum=momentum)\n",
    "    train_op = optimizer.minimize(loss,\n",
    "                       global_step=global_step)\n",
    "    return train_op,learning_rate_now\n",
    "\n",
    "def placeholder_inputs(batch_size):\n",
    "    \n",
    "#     return the packed input samples and labels at batch_size\n",
    "\n",
    "    inputs_placeholder = tf.placeholder(tf.float32,shape=(None,4))\n",
    "    \n",
    "    labels_placeholder = tf.placeholder(tf.int32,shape=(None))\n",
    "    \n",
    "    return inputs_placeholder, labels_placeholder\n",
    "\n",
    "# have bugs here\n",
    "def full_fill_dict(dataset,inputs_placeholder,labels_placeholder):\n",
    "#     the arguments should be placehold type\n",
    "    inputs,labels = trainDataset.next_batch()\n",
    "    return {\n",
    "        inputs_placeholder:inputs,\n",
    "        labels_placeholder:labels,\n",
    "    }\n",
    "    \n",
    "def do_eval(sess,\n",
    "            dataset,\n",
    "            eval_correct,\n",
    "            inputs_placeholder,\n",
    "            labels_placeholder):\n",
    "#     dataset should be test dataset and eval_correct is just a Variable for testing\n",
    "#     here we test all samples in testdataset\n",
    "    \n",
    "#     sum_correct = 0\n",
    "    sum_all = dataset.data_size\n",
    "#     for step in range(max_step):\n",
    "        \n",
    "    data_all = dataset.feed_all()\n",
    "    \n",
    "    feed_dict = {\n",
    "    inputs_placeholder:data_all[0],\n",
    "    labels_placeholder:data_all[1]\n",
    "    }\n",
    "    sum_correct =sess.run(eval_correct,feed_dict=feed_dict)\n",
    "    precision = float(sum_correct) / sum_all\n",
    "    \n",
    "#               evaluation in test dataset here\n",
    "\n",
    "    print('  Num examples: %d  Num correct: %d  Precision @ 1: %0.04f' %\n",
    "    (sum_all, sum_correct, precision))\n",
    "    return precision\n",
    "\n",
    "def run_training(batch_size,\n",
    "                 learning_rate,\n",
    "                 hidden_units,\n",
    "                 max_steps):\n",
    "#     prepare to train\n",
    "    \n",
    "#     build the graph of nn\n",
    "    inputs_placeholder , labels_placeholder = placeholder_inputs(batch_size) \n",
    "    \n",
    "    logits = inference(inputs_placeholder,hidden_units)\n",
    "    \n",
    "#     be used during training for updating weights and biases\n",
    "    loss = getloss(logits,labels_placeholder)\n",
    "    \n",
    "#     be used during testing for evaluating performance of model\n",
    "    eval_correct = evaluate(logits,labels_placeholder)\n",
    "    \n",
    "#     get the train operation\n",
    "    train_op,learning_rate_now = training(loss,learning_rate)\n",
    "    \n",
    "#     create Dataset class for convience to use\n",
    "    trainDataset = Dataset(train_dataset,\n",
    "                           batch_size,\n",
    "                           'train')\n",
    "    \n",
    "    testDataset = Dataset(test_dataset,\n",
    "                          batch_size,\n",
    "                          'test')\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    \n",
    "    loss_all = []\n",
    "    \n",
    "    accuracy_all = []\n",
    "    \n",
    "#     must put at last\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess.run(init)\n",
    "    for step in range(max_steps):\n",
    "        \n",
    "#         train here\n",
    "#         get the samples from train dataset to feed \n",
    "        feed_dict = full_fill_dict(trainDataset,\n",
    "                                   inputs_placeholder,\n",
    "                                  labels_placeholder\n",
    "                                  )\n",
    "#         inputs,labels = trainDataset.next_batch()\n",
    "#         feed_dict = {\n",
    "#             inputs_placeholder:inputs,\n",
    "#             labels_placeholder:labels,\n",
    "#         }\n",
    "        _ , loss_value,learning_rate_tensor_value = sess.run([train_op,\n",
    "                                                              loss,\n",
    "                                                              learning_rate_now],\n",
    "                                 feed_dict=feed_dict)\n",
    "        \n",
    "        loss_all.append(loss_value)\n",
    "        \n",
    "        if (step %100==0):\n",
    "            \n",
    "#             print status here\n",
    "            print('Step %d: loss = %.5f learning_rate = %.5f' % (step,\n",
    "                                                                 loss_value,\n",
    "                                                                 learning_rate_tensor_value))\n",
    "            \n",
    "            \n",
    "        if((step + 1) %200==0 or (step + 1) == max_steps):\n",
    "\n",
    "            print('Testing Data eval:')\n",
    "\n",
    "            precision = do_eval(sess,\n",
    "                    testDataset,\n",
    "                    eval_correct,\n",
    "                    inputs_placeholder,\n",
    "                    labels_placeholder)\n",
    "            accuracy_all.append(precision)\n",
    "            \n",
    "#     plot graph for training and testing\n",
    "# loss\n",
    "    plt.figure(1)\n",
    "#     plt.subplot(111)\n",
    "    plt.plot(range(len(loss_all)),loss_all)\n",
    "    plt.title('loss')\n",
    "#   \n",
    "    plt.figure(2)\n",
    "#     plt.subplot(211)\n",
    "    plt.plot(range(len(accuracy_all)),accuracy_all)\n",
    "    plt.title('accuracy')\n",
    "    \n",
    "    plt.show()\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: loss = 0.90567 learning_rate = 0.00100\n",
      "Step 100: loss = 0.13238 learning_rate = 0.00100\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 28  Precision @ 1: 0.9333\n",
      "Step 200: loss = 0.00586 learning_rate = 0.00100\n",
      "Step 300: loss = 0.17136 learning_rate = 0.00100\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 16  Precision @ 1: 0.5333\n",
      "Step 400: loss = 0.00617 learning_rate = 0.00100\n",
      "Step 500: loss = 0.00523 learning_rate = 0.00100\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 23  Precision @ 1: 0.7667\n",
      "Step 600: loss = 0.00331 learning_rate = 0.00100\n",
      "Step 700: loss = 0.00083 learning_rate = 0.00100\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 800: loss = 0.00125 learning_rate = 0.00100\n",
      "Step 900: loss = 0.23907 learning_rate = 0.00100\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 20  Precision @ 1: 0.6667\n",
      "Step 1000: loss = 0.01238 learning_rate = 0.00100\n",
      "Step 1100: loss = 0.00161 learning_rate = 0.00100\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 28  Precision @ 1: 0.9333\n",
      "Step 1200: loss = 0.00308 learning_rate = 0.00100\n",
      "Step 1300: loss = 0.00098 learning_rate = 0.00100\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 1400: loss = 0.00135 learning_rate = 0.00100\n",
      "Step 1500: loss = 0.01099 learning_rate = 0.00100\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 28  Precision @ 1: 0.9333\n",
      "Step 1600: loss = 0.08619 learning_rate = 0.00100\n",
      "Step 1700: loss = 0.00052 learning_rate = 0.00100\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 30  Precision @ 1: 1.0000\n",
      "Step 1800: loss = 0.00092 learning_rate = 0.00100\n",
      "Step 1900: loss = 0.00030 learning_rate = 0.00100\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 2000: loss = 0.00089 learning_rate = 0.00100\n",
      "Step 2100: loss = 0.00093 learning_rate = 0.00100\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 28  Precision @ 1: 0.9333\n",
      "Step 2200: loss = 0.02095 learning_rate = 0.00100\n",
      "Step 2300: loss = 0.00019 learning_rate = 0.00100\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 2400: loss = 0.00049 learning_rate = 0.00100\n",
      "Step 2500: loss = 0.00024 learning_rate = 0.00100\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 2600: loss = 0.00077 learning_rate = 0.00100\n",
      "Step 2700: loss = 0.00028 learning_rate = 0.00100\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 28  Precision @ 1: 0.9333\n",
      "Step 2800: loss = 0.01432 learning_rate = 0.00100\n",
      "Step 2900: loss = 0.00012 learning_rate = 0.00100\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 28  Precision @ 1: 0.9333\n",
      "Step 3000: loss = 0.00036 learning_rate = 0.00100\n",
      "Step 3100: loss = 0.00025 learning_rate = 0.00100\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 3200: loss = 0.00077 learning_rate = 0.00100\n",
      "Step 3300: loss = 0.00011 learning_rate = 0.00100\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 28  Precision @ 1: 0.9333\n",
      "Step 3400: loss = 0.01305 learning_rate = 0.00100\n",
      "Step 3500: loss = 0.00009 learning_rate = 0.00100\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 28  Precision @ 1: 0.9333\n",
      "Step 3600: loss = 0.00026 learning_rate = 0.00100\n",
      "Step 3700: loss = 0.00018 learning_rate = 0.00100\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 3800: loss = 0.00069 learning_rate = 0.00100\n",
      "Step 3900: loss = 0.00007 learning_rate = 0.00100\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 28  Precision @ 1: 0.9333\n",
      "Step 4000: loss = 0.02668 learning_rate = 0.00010\n",
      "Step 4100: loss = 0.00010 learning_rate = 0.00010\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 4200: loss = 0.00028 learning_rate = 0.00010\n",
      "Step 4300: loss = 0.00010 learning_rate = 0.00010\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 4400: loss = 0.00037 learning_rate = 0.00010\n",
      "Step 4500: loss = 0.00334 learning_rate = 0.00010\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 30  Precision @ 1: 1.0000\n",
      "Step 4600: loss = 0.09630 learning_rate = 0.00010\n",
      "Step 4700: loss = 0.00010 learning_rate = 0.00010\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 4800: loss = 0.00030 learning_rate = 0.00010\n",
      "Step 4900: loss = 0.00010 learning_rate = 0.00010\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 5000: loss = 0.00038 learning_rate = 0.00010\n",
      "Step 5100: loss = 0.00277 learning_rate = 0.00010\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 30  Precision @ 1: 1.0000\n",
      "Step 5200: loss = 0.08724 learning_rate = 0.00010\n",
      "Step 5300: loss = 0.00010 learning_rate = 0.00010\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 5400: loss = 0.00028 learning_rate = 0.00010\n",
      "Step 5500: loss = 0.00010 learning_rate = 0.00010\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 5600: loss = 0.00035 learning_rate = 0.00010\n",
      "Step 5700: loss = 0.00246 learning_rate = 0.00010\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 30  Precision @ 1: 1.0000\n",
      "Step 5800: loss = 0.08108 learning_rate = 0.00010\n",
      "Step 5900: loss = 0.00009 learning_rate = 0.00010\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 6000: loss = 0.00026 learning_rate = 0.00010\n",
      "Step 6100: loss = 0.00008 learning_rate = 0.00010\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 6200: loss = 0.00031 learning_rate = 0.00010\n",
      "Step 6300: loss = 0.00219 learning_rate = 0.00010\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 30  Precision @ 1: 1.0000\n",
      "Step 6400: loss = 0.07662 learning_rate = 0.00010\n",
      "Step 6500: loss = 0.00008 learning_rate = 0.00010\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 6600: loss = 0.00023 learning_rate = 0.00010\n",
      "Step 6700: loss = 0.00007 learning_rate = 0.00010\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 6800: loss = 0.00028 learning_rate = 0.00010\n",
      "Step 6900: loss = 0.00202 learning_rate = 0.00010\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 30  Precision @ 1: 1.0000\n",
      "Step 7000: loss = 0.07373 learning_rate = 0.00010\n",
      "Step 7100: loss = 0.00007 learning_rate = 0.00010\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 7200: loss = 0.00021 learning_rate = 0.00010\n",
      "Step 7300: loss = 0.00007 learning_rate = 0.00010\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 7400: loss = 0.00025 learning_rate = 0.00010\n",
      "Step 7500: loss = 0.00191 learning_rate = 0.00010\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 30  Precision @ 1: 1.0000\n",
      "Step 7600: loss = 0.07103 learning_rate = 0.00010\n",
      "Step 7700: loss = 0.00006 learning_rate = 0.00010\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 7800: loss = 0.00019 learning_rate = 0.00010\n",
      "Step 7900: loss = 0.00006 learning_rate = 0.00010\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 8000: loss = 0.00023 learning_rate = 0.00001\n",
      "Step 8100: loss = 0.00229 learning_rate = 0.00001\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 8200: loss = 0.04666 learning_rate = 0.00001\n",
      "Step 8300: loss = 0.00006 learning_rate = 0.00001\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 30  Precision @ 1: 1.0000\n",
      "Step 8400: loss = 0.00018 learning_rate = 0.00001\n",
      "Step 8500: loss = 0.00006 learning_rate = 0.00001\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 30  Precision @ 1: 1.0000\n",
      "Step 8600: loss = 0.00025 learning_rate = 0.00001\n",
      "Step 8700: loss = 0.00539 learning_rate = 0.00001\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 8800: loss = 0.07533 learning_rate = 0.00001\n",
      "Step 8900: loss = 0.00006 learning_rate = 0.00001\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 9000: loss = 0.00018 learning_rate = 0.00001\n",
      "Step 9100: loss = 0.00006 learning_rate = 0.00001\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 9200: loss = 0.00025 learning_rate = 0.00001\n",
      "Step 9300: loss = 0.00582 learning_rate = 0.00001\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 9400: loss = 0.07844 learning_rate = 0.00001\n",
      "Step 9500: loss = 0.00006 learning_rate = 0.00001\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 9600: loss = 0.00018 learning_rate = 0.00001\n",
      "Step 9700: loss = 0.00006 learning_rate = 0.00001\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n",
      "Step 9800: loss = 0.00025 learning_rate = 0.00001\n",
      "Step 9900: loss = 0.00575 learning_rate = 0.00001\n",
      "Testing Data eval:\n",
      "  Num examples: 30  Num correct: 29  Precision @ 1: 0.9667\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAFyCAYAAAB/b0lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd5e8067e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAFyCAYAAAB/b0lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd57c0c2a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "run_training(2,0.001,[10,20,10],10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.train.MomentumOptimizer?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
